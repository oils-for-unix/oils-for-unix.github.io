  <!DOCTYPE html>
  <html>
    <head>
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <title>Parsing is Difficult</title>
      <link rel="stylesheet" type="text/css" href="../web/base.css" />
    </head>
    <body class="width40">

<p>Blog Theme</p>
<p><a href="Language-Design-and-Theory-of-Computation.html">Language Design and Theory of Computation</a> -- CFGs aren't powerful enough.  Java has two grammars.</p>
<p><a href="Why-Lexing-and-Parsing-Should-Be-Separate.html">Why Lexing and Parsing Should Be Separate</a> -- criticism of PEGs</p>
<p>https://news.ycombinator.com/item?id=13821829 -- Real parsers are hand-written; they use code generators or meta-languages.</p>
<p>https://news.ycombinator.com/item?id=13041646 -- metalanguage feedback in response to old META II paper.  Ruby parser is complex.  JRuby parser is an example of writing two parsers.</p>
<p>https://news.ycombinator.com/item?id=13630686 -- my own metalanguage</p>
<p>https://news.ycombinator.com/item?id=15713825 -- someone who thinks parsing languages is simpler than it actually is (regarding language server protocol)</p>
<p>https://news.ycombinator.com/item?id=14379114 -- Walter Bright overstating the applicability of CFGs</p>
<p>Note about error messages: are parse errors really hard?  They all seem similar, as long as you have location info?  Python doesn't seem to have any special handling of parse errors.  It uses a grammmar.</p>
<p>I think type-checking error messages are hard, like Clang diagnostics.  And runtime errors to an extent.  But parse errors may be easy if the language is straightforward enough.</p>
<p>The one place I might want an advanced error message is for <code>$((</code>.  You want to know where it started thinking of things as arithmetic.  The place you fix is different than <strong>the place the error occurred</strong>.</p>
<ul>
<li>My reply to someone who says parsing is easy, with points from this page: <a href="Parsing-Is-Not-Solved%7Chttps://www.reddit.com/r/ProgrammingLanguages/comments/7k9qni/what_do_you_think_about_structured_editing/drdd1y3/.html">Parsing Is Not Solved|https://www.reddit.com/r/ProgrammingLanguages/comments/7k9qni/what_do_you_think_about_structured_editing/drdd1y3/</a>
<ul>
<li>another point: Microsoft and JetBrains have parsing technology that is beyond the state of the art in open source.  It's still advancing.</li>
</ul>
</li>
</ul>
<h3>Real Languages have at least Two Parsers</h3>
<ul>
<li>
<p>Python: CPython parser, lib2to3, redbaron</p>
</li>
<li>
<p>Ruby: MRI parser, JRuby parser</p>
</li>
<li>
<p>Go: C parser, Go parser</p>
</li>
<li>
<p>Scala: seems like scala-meta might have another parser</p>
</li>
<li>
<p>JavaScript: many different parsers</p>
</li>
<li>
<p>Unified parsers:</p>
<ul>
<li>Clang</li>
<li>Roslyn</li>
</ul>
</li>
<li>
<p>SQL:</p>
<ul>
<li><a href="A-third-party-parser-for-Postgres-SQL%7Chttps://news.ycombinator.com/item?id=16496130.html">A third party parser for Postgres SQL|https://news.ycombinator.com/item?id=16496130</a></li>
<li>https://github.com/uber/queryparser/blob/master/dialects/hive/src/Database/Sql/Hive/Parser.hs -- it's written in Haskell with Parsec, like ShellCheck</li>
<li><em>It's a pity that the thing has to get reimplemented all over so many times. For example, you'd think you could reuse PostgreSQL's parser, but its code is autogenerated and riddled with side effects</em> -- not side effects per se, but semantic actions that are embedded in the grammar.  <code>gram.y</code> is 16K+ lines!!!</li>
</ul>
</li>
</ul>
<p>From coverage.py.  The Python stdlib tokenizer isn't good enough, because it's not lossless!  It's also a second tokenizer, since the C one is not wrapped.</p>
<pre><code>def phys_tokens(toks):
    &quot;&quot;&quot;Return all physical tokens, even line continuations.

    tokenize.generate_tokens() doesn't return a token for the backslash that
    continues lines.  This wrapper provides those tokens so that we can
    re-create a faithful representation of the original source.

    Returns the same values as generate_tokens()
</code></pre>
<ul>
<li>TODO: Look at the list of linters here: https://github.com/mcandre/linters
<ul>
<li>what parsers do they use?</li>
</ul>
</li>
</ul>
<h3>Parsing is Slow</h3>
<ul>
<li>Binary AST format proposal: https://github.com/syg/ecmascript-binary-ast</li>
<li>v8 has eager and lazy parsers (see YouTube video)</li>
<li>Streaming Compilation with WebAssembly -- contrast with JavaScript: https://news.ycombinator.com/item?id=16169236</li>
</ul>
<p>Well another takeaway is that people ship a lot of JavaScript over the wire that they never use!!!</p>
<h3>Blog Outline</h3>
<ul>
<li>
<p>The state of the art is hand-written parsers</p>
</li>
<li>
<p>The state of the art is two hand-written parsers (possibly written to the same spec, or not)</p>
</li>
<li>
<p>The state of the art is two grammars?  (TODO: Look at Java).  Grammars are no longer declarative.</p>
</li>
<li>
<p>State of the art:</p>
<ul>
<li>v8 and Clang for performance</li>
<li>TypeScript / C# for generality</li>
<li>v8 for safety?  any others?</li>
</ul>
</li>
</ul>
<h3>Gaps Between Theory and Practice</h3>
<ul>
<li>https://www.reddit.com/r/ProgrammingLanguages/comments/74ktjg/what_compromises_have_you_made/do0rsku/ -- In theory, parsing is about testing whether a language is in a set.  In practice, it's also about creating an AST/LST structure.  This is where the concept of &quot;ambiguity&quot; arises -- more than one possible sequence of productions can lead to the same string.
<ul>
<li>It's also analogous to the &quot;group capture&quot; problem in regular expressions.  We want to retain linear time performance and specify greedy/nongreedy behavior when extracting substrings: https://swtch.com/~rsc/regexp/</li>
</ul>
</li>
</ul>
<h3>Parsing Requires Little Tricks</h3>
<ul>
<li>Operator Precedence Parsing, even though C grammars can manually encode it (https://news.ycombinator.com/item?id=15470988)</li>
<li>Handling left-recursive rules in a recursive descent parser: https://tavianator.com/bfs-from-the-ground-up-2/
<ul>
<li>Matters for shell's equal-precedence <code>||</code> and <code>&amp;&amp;</code></li>
<li>this is the difference between treating a parsing as set membership vs. creating a useful tree structure</li>
</ul>
</li>
<li>Parse Tree vs. AST vs. LST (<a href="Lossless-Syntax-Tree-Pattern.html">Lossless Syntax Tree Pattern</a>)
<ul>
<li>these are punted onto semantic actions</li>
</ul>
</li>
<li>backtracking or predictive recursive descent?
<ul>
<li>lookahead?</li>
</ul>
</li>
<li>C's context sensitivity (types vs. identifiers)</li>
<li>dangling else problem (the canonical example of a shift-reduce conflict)
<ul>
<li>Is Java Context Free?  <a href="https://www.reddit.com/r/ProgrammingLanguages/comments/7gvdje/any_advice_on_how_to_implement_the_pythonindent/drd3v0u/">My comments on Reddit</a></li>
</ul>
</li>
</ul>
<p>Contrast with paper: Pure Declarative Syntax Lost and Regained.</p>
<h3>Many Parsers Parse Twice</h3>
<ul>
<li>Python does this silly thing where it re-parses its own tokens.  For example, strings, multiline strings, raw strings, byte strings, etc.
<ul>
<li>See <code>astcompiler/astbuilder.py</code> module in in PyPy!  It calls <code>parse_number()</code> and uses the <code>parsestring</code> module.</li>
<li>See <code>parsestring()</code> and <code>parsenumber()</code> functions in <code>Python/ast.c</code>.  Wow I can't believe they do this!</li>
<li>Better solution: use lexer state.  String literals are their own language with C escapes.</li>
<li>Conclusion: <strong>The Lexer/Parser interface is broken</strong>.  Lexer modes are better!
<ul>
<li>for string literals</li>
<li>for numeric literals</li>
</ul>
</li>
</ul>
</li>
<li>Bash also parsers code twice -- to find the end of <code>$(</code>, <code>$((</code>, etc. and then to parse what's inside it!</li>
</ul>
<h3>Idea for Parsing Tool</h3>
<ul>
<li>Stateful lexer -- generalization of regular lexer.
<ul>
<li>it's meant to handle <code>\n</code> in strings,  1.0e100 in numbers, etc.</li>
</ul>
</li>
<li>LL(k) for efficiency</li>
<li>pratt parsing (or shunting yard) for efficiency and compact description of a grammar</li>
<li>LR(k) for C, Awk, maybe Ruby, R, etc.
<ul>
<li>TODO: research the ways in which LL(k) is not sufficient for those languages?</li>
<li>we know about C prototypes declarations vs. definitions.  This is LR(k), but requires infinite k for LL(k).</li>
<li>JavaScript <code>=&gt;</code> function.</li>
</ul>
</li>
<li>Zephyr ASDL for abstract syntax and <a href="Lossless-Syntax-Tree-Pattern.html">Lossless Syntax Tree Pattern</a></li>
<li>what language for semantic actions?  Maybe reuse the OVM data structures and library?  OVM could be based on
algebraic data types?</li>
</ul>
<h3>Papers</h3>
<ul>
<li>A Simple, Possibly Correct Parser for C11.  They use OCaml lex, menhir, and a Context object to do the &quot;lexical feedback&quot;.  The <strong>Related Work</strong> section at the end is very good.</li>
</ul>
<h3>Parsing Network Protocols Is Also Difficult</h3>
<p>langsec line of research is using the wrong formalism.  The update on calc-regular languages is immature and can't express things like varint decoding (AFAICT):</p>
<p>https://news.ycombinator.com/item?id=16126234</p>
<h3>Related Articles</h3>
<ul>
<li>http://duriansoftware.com/joe/Constructing-human-grade-parsers.html</li>
</ul>
  </body>
</html>

